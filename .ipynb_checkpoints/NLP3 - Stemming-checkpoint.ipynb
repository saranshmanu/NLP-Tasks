{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: It  Stem: It\n",
      "Actual: originated  Stem: origin\n",
      "Actual: from  Stem: from\n",
      "Actual: the  Stem: the\n",
      "Actual: idea  Stem: idea\n",
      "Actual: that  Stem: that\n",
      "Actual: there  Stem: there\n",
      "Actual: are  Stem: are\n",
      "Actual: readers  Stem: reader\n",
      "Actual: who  Stem: who\n",
      "Actual: prefer  Stem: prefer\n",
      "Actual: learning  Stem: learn\n",
      "Actual: new  Stem: new\n",
      "Actual: skills  Stem: skill\n",
      "Actual: from  Stem: from\n",
      "Actual: the  Stem: the\n",
      "Actual: comforts  Stem: comfort\n",
      "Actual: of  Stem: of\n",
      "Actual: their  Stem: their\n",
      "Actual: drawing  Stem: draw\n",
      "Actual: rooms  Stem: room\n",
      "Actual: .  Stem: .\n",
      "Actual: Lilies  Stem: lili\n",
      "Actual: are  Stem: are\n",
      "Actual: pretty  Stem: pretti\n",
      "Actual: .  Stem: .\n",
      "\n",
      "\n",
      "After porter stemming we get: It origin from the idea that there are reader who prefer learn new skill from the comfort of their draw room . lili are pretti .\n"
     ]
    }
   ],
   "source": [
    "document_1 = []\n",
    "word_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms. Lilies are pretty.\"\n",
    "# First Word tokenization\n",
    "nltk_tokens = nltk.word_tokenize(word_data)\n",
    "#Next find the roots of the word\n",
    "for w in nltk_tokens:\n",
    "    print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))\n",
    "    document_1.append(porter_stemmer.stem(w))\n",
    "\n",
    "print('\\n')\n",
    "port = ' '.join(word for word in document_1)\n",
    "print(\"After porter stemming we get:\",port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: It  Lancaster: it\n",
      "Actual: originated  Lancaster: origin\n",
      "Actual: from  Lancaster: from\n",
      "Actual: the  Lancaster: the\n",
      "Actual: idea  Lancaster: ide\n",
      "Actual: that  Lancaster: that\n",
      "Actual: there  Lancaster: ther\n",
      "Actual: are  Lancaster: ar\n",
      "Actual: reader  Lancaster: read\n",
      "Actual: who  Lancaster: who\n",
      "Actual: prefer  Lancaster: pref\n",
      "Actual: learning  Lancaster: learn\n",
      "Actual: new  Lancaster: new\n",
      "Actual: skill  Lancaster: skil\n",
      "Actual: from  Lancaster: from\n",
      "Actual: the  Lancaster: the\n",
      "Actual: comfort  Lancaster: comfort\n",
      "Actual: of  Lancaster: of\n",
      "Actual: their  Lancaster: their\n",
      "Actual: drawing  Lancaster: draw\n",
      "Actual: room  Lancaster: room\n",
      "Actual: .  Lancaster: .\n",
      "Actual: Lilies  Lancaster: lily\n",
      "Actual: are  Lancaster: ar\n",
      "Actual: pretty  Lancaster: pretty\n",
      "Actual: .  Lancaster: .\n",
      "\n",
      "\n",
      "After lemmatization and Lancaster stemming we get: it origin from the ide that ther ar read who pref learn new skil from the comfort of their draw room . lily ar pretty .\n"
     ]
    }
   ],
   "source": [
    "document_3 = []\n",
    "from nltk.stem import LancasterStemmer \n",
    "stemmerLan = LancasterStemmer() \n",
    "nltk_tokens = nltk.word_tokenize(lem)\n",
    "for w in nltk_tokens:\n",
    "    print(\"Actual: %s  Lancaster: %s\"  % (w,stemmerLan.stem(w)))\n",
    "    document_3.append(stemmerLan.stem(w))\n",
    "    \n",
    "print('\\n')\n",
    "lanc = ' '.join(word for word in document_3)\n",
    "print(\"After lemmatization and Lancaster stemming we get:\",lanc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "vector1 = text_to_vector(port)\n",
    "vector2 = text_to_vector(lem)\n",
    "\n",
    "cosine = get_cosine(vector1, vector2)\n",
    "\n",
    "print('Cosine:', cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: It  Lemma: It\n",
      "Actual: originated  Lemma: originated\n",
      "Actual: from  Lemma: from\n",
      "Actual: the  Lemma: the\n",
      "Actual: idea  Lemma: idea\n",
      "Actual: that  Lemma: that\n",
      "Actual: there  Lemma: there\n",
      "Actual: are  Lemma: are\n",
      "Actual: readers  Lemma: reader\n",
      "Actual: who  Lemma: who\n",
      "Actual: prefer  Lemma: prefer\n",
      "Actual: learning  Lemma: learning\n",
      "Actual: new  Lemma: new\n",
      "Actual: skills  Lemma: skill\n",
      "Actual: from  Lemma: from\n",
      "Actual: the  Lemma: the\n",
      "Actual: comforts  Lemma: comfort\n",
      "Actual: of  Lemma: of\n",
      "Actual: their  Lemma: their\n",
      "Actual: drawing  Lemma: drawing\n",
      "Actual: rooms  Lemma: room\n",
      "Actual: .  Lemma: .\n",
      "Actual: Lilies  Lemma: Lilies\n",
      "Actual: are  Lemma: are\n",
      "Actual: pretty  Lemma: pretty\n",
      "Actual: .  Lemma: .\n",
      "\n",
      "\n",
      "After lemmatization we get: It originated from the idea that there are reader who prefer learning new skill from the comfort of their drawing room . Lilies are pretty .\n"
     ]
    }
   ],
   "source": [
    "document_2 = []\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk_tokens = nltk.word_tokenize(word_data)\n",
    "for w in nltk_tokens:\n",
    "    print(\"Actual: %s  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))\n",
    "    document_2.append(wordnet_lemmatizer.lemmatize(w))\n",
    "\n",
    "print('\\n')\n",
    "lem = ' '.join(word for word in document_2)\n",
    "print(\"After lemmatization we get:\",lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "print(\" \".join(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(stemmer.stem(\"workings\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
